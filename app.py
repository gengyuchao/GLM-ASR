import argparse
import threading
import tempfile
import os
import json
import time
from pathlib import Path
import torch
import torchaudio
import numpy as np
from transformers import (
    AutoConfig,
    AutoModelForCausalLM,
    AutoTokenizer,
    WhisperFeatureExtractor,
)
from flask import Flask, request, render_template_string, jsonify
import traceback

# ========== åŸå§‹å‡½æ•°å®Œæ•´å®ç° ==========
WHISPER_FEAT_CFG = {
    "chunk_length": 30,
    "feature_extractor_type": "WhisperFeatureExtractor",
    "feature_size": 128,
    "hop_length": 160,
    "n_fft": 400,
    "n_samples": 480000,
    "nb_max_frames": 3000,
    "padding_side": "right",
    "padding_value": 0.0,
    "processor_class": "WhisperProcessor",
    "return_attention_mask": False,
    "sampling_rate": 16000,
}

def get_audio_token_length(seconds, merge_factor=2):
    def get_T_after_cnn(L_in, dilation=1):
        for padding, kernel_size, stride in [(1,3,1)] + [(1,3,2)]:
            L_out = L_in + 2 * padding - dilation * (kernel_size - 1) - 1
            L_out = 1 + L_out // stride
            L_in = L_out
        return L_out

    mel_len = int(seconds * 100)
    audio_len_after_cnn = get_T_after_cnn(mel_len)
    audio_token_num = (audio_len_after_cnn - merge_factor) // merge_factor + 1
    audio_token_num = min(audio_token_num, 1500 // merge_factor)
    return audio_token_num

def build_prompt(
    audio_path: Path,
    tokenizer,
    feature_extractor: WhisperFeatureExtractor,
    merge_factor: int,
    chunk_seconds: int = 30,
) -> dict:
    audio_path = Path(audio_path)
    wav, sr = torchaudio.load(str(audio_path))
    wav = wav[:1, :]  # åªå–å•å£°é“

    # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
    if sr != feature_extractor.sampling_rate:
        wav = torchaudio.transforms.Resample(sr, feature_extractor.sampling_rate)(wav)

    tokens = []
    tokens += tokenizer.encode("<|user|>")
    tokens += tokenizer.encode("\n")

    audios = []
    audio_offsets = []
    audio_length = []
    chunk_size = chunk_seconds * feature_extractor.sampling_rate
    
    # å°†éŸ³é¢‘åˆ†å‰²æˆå—å¤„ç†
    for start in range(0, wav.shape[1], chunk_size):
        chunk = wav[:, start:start + chunk_size]
        mel = feature_extractor(
            chunk.numpy(),
            sampling_rate=feature_extractor.sampling_rate,
            return_tensors="pt",
            padding="max_length",
        )["input_features"]
        audios.append(mel)
        
        seconds = chunk.shape[1] / feature_extractor.sampling_rate
        num_tokens = get_audio_token_length(seconds, merge_factor)
        
        tokens += tokenizer.encode("<|begin_of_audio|>")
        audio_offsets.append(len(tokens))
        tokens += [0] * num_tokens
        tokens += tokenizer.encode("<|end_of_audio|>")
        audio_length.append(num_tokens)

    if not audios:
        raise ValueError("éŸ³é¢‘å†…å®¹ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ã€‚")

    # æ·»åŠ æç¤ºæ–‡æœ¬
    tokens += tokenizer.encode("<|user|>")
    tokens += tokenizer.encode("\nPlease transcribe this audio into text")
    tokens += tokenizer.encode("<|assistant|>")
    tokens += tokenizer.encode("\n")

    batch = {
        "input_ids": torch.tensor([tokens], dtype=torch.long),
        "audios": torch.cat(audios, dim=0),
        "audio_offsets": [audio_offsets],
        "audio_length": [audio_length],
        "attention_mask": torch.ones(1, len(tokens), dtype=torch.long),
    }
    return batch

def prepare_inputs(batch: dict, device: torch.device) -> tuple[dict, int]:
    tokens = batch["input_ids"].to(device)
    attention_mask = batch["attention_mask"].to(device)
    audios = batch["audios"].to(device)
    model_inputs = {
        "inputs": tokens,
        "attention_mask": attention_mask,
        "audios": audios.to(torch.bfloat16),
        "audio_offsets": batch["audio_offsets"],
        "audio_length": batch["audio_length"],
    }
    return model_inputs, tokens.size(1)

# ========== å…¨å±€å˜é‡ ==========
app = Flask(__name__)
model = None
tokenizer = None
feature_extractor = None
config = None
device = None
model_lock = threading.Lock()
model_loaded = False
model_error = None

@app.route('/')
def index():
    return render_template_string("""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>è¯­éŸ³è½¬æ–‡å­—</title>
        <style>
            :root {
                --primary: #4361ee;
                --secondary: #3f37c9;
                --success: #10b981;
                --danger: #ef4444;
                --warning: #f59e0b;
                --light: #f8f9fa;
                --dark: #212529;
                --gray: #6b7280;
            }
            body { 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                max-width: 800px; 
                margin: 0 auto; 
                padding: 1.5rem;
                background-color: #f5f7fa;
                color: #333;
                line-height: 1.6;
            }
            .container {
                background: white;
                border-radius: 16px;
                padding: 2rem;
                box-shadow: 0 10px 30px rgba(0,0,0,0.08);
                margin-top: 1rem;
            }
            h1 {
                color: var(--dark);
                text-align: center;
                margin-bottom: 1rem;
                font-weight: 700;
                font-size: 2rem;
            }
            .tab-container {
                display: flex;
                margin-bottom: 1.5rem;
                border-bottom: 2px solid #e2e8f0;
            }
            .tab {
                padding: 0.8rem 1.5rem;
                cursor: pointer;
                font-weight: 500;
                border-bottom: 3px solid transparent;
                transition: all 0.3s ease;
            }
            .tab.active {
                color: var(--primary);
                border-bottom: 3px solid var(--primary);
            }
            .tab-content {
                display: none;
            }
            .tab-content.active {
                display: block;
            }
            .status-container {
                text-align: center;
                margin: 1.2rem 0;
                min-height: 2rem;
                padding: 0.8rem;
                border-radius: 8px;
                background: #f1f5f9;
                font-weight: 500;
                color: #4b5563;
                display: flex;
                align-items: center;
                justify-content: center;
                gap: 8px;
            }
            .status-error {
                background: #fee2e2;
                color: #b91c1c;
                text-align: left;
                font-family: monospace;
                white-space: pre-wrap;
                max-height: 200px;
                overflow-y: auto;
                padding: 1rem;
                margin-top: 1rem;
                border-radius: 8px;
                border-left: 4px solid var(--danger);
            }
            .recording-indicator {
                display: inline-block;
                width: 16px;
                height: 16px;
                border-radius: 50%;
                background: var(--danger);
                margin-right: 8px;
                vertical-align: middle;
                opacity: 0;
                transition: opacity 0.3s ease;
            }
            .recording-indicator.active {
                opacity: 1;
                box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
                animation: pulse 1.5s infinite;
            }
            @keyframes pulse {
                0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
                70% { box-shadow: 0 0 0 12px rgba(239, 68, 68, 0); }
                100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
            }
            .permission-message {
                background: #fff9db;
                color: #8a6d3b;
                padding: 1rem;
                border-radius: 8px;
                margin: 1rem 0;
                border: 1px solid #faebcc;
                display: none;
            }
            .btn {
                background: var(--primary);
                color: white;
                border: none;
                padding: 14px 28px;
                font-size: 1.1rem;
                border-radius: 12px;
                cursor: pointer;
                transition: all 0.3s ease;
                font-weight: 600;
                box-shadow: 0 4px 15px rgba(67, 97, 238, 0.35);
                display: flex;
                align-items: center;
                justify-content: center;
                gap: 8px;
                width: 100%;
                max-width: 400px;
                margin: 0 auto;
            }
            .btn:hover:not(:disabled) {
                background: var(--secondary);
                transform: translateY(-2px);
                box-shadow: 0 6px 20px rgba(67, 97, 238, 0.45);
            }
            .btn:active:not(:disabled) {
                transform: translateY(1px);
            }
            .btn:disabled {
                background: #9ca3af;
                cursor: not-allowed;
                transform: none;
                box-shadow: none;
                opacity: 0.8;
            }
            .btn-record {
                background: var(--primary);
            }
            .btn-record.recording {
                background: var(--danger);
                animation: glow 2s infinite;
            }
            @keyframes glow {
                0% { box-shadow: 0 0 10px rgba(239, 68, 68, 0.6); }
                50% { box-shadow: 0 0 20px rgba(239, 68, 68, 0.8); }
                100% { box-shadow: 0 0 10px rgba(239, 68, 68, 0.6); }
            }
            .btn-upload {
                background: var(--success);
                margin-top: 1rem;
            }
            .btn-upload:hover:not(:disabled) {
                background: #0da271;
            }
            .btn-cancel {
                background: var(--gray);
                margin-top: 1rem;
            }
            .btn-cancel:hover:not(:disabled) {
                background: #4b5563;
            }
            #transcript {
                margin-top: 1.5rem;
                padding: 1.5rem;
                border-radius: 12px;
                background: var(--light);
                min-height: 100px;
                border: 2px dashed #cbd5e1;
                line-height: 1.7;
                font-size: 1.1rem;
                color: var(--dark);
                transition: all 0.3s ease;
                word-break: break-word;
                position: relative;
                /* ä¿®å¤æ¢è¡Œé—®é¢˜çš„å…³é”®CSS */
                white-space: pre-wrap;
                overflow-wrap: break-word;
            }
            #transcript.processing {
                border-color: var(--primary);
                background: #eef4ff;
                min-height: 80px;
            }
            .segment-marker {
                position: absolute;
                top: 0;
                right: 10px;
                background: var(--warning);
                color: white;
                padding: 2px 6px;
                border-radius: 10px;
                font-size: 0.8rem;
                font-weight: bold;
            }
            .progress-container {
                margin: 1.5rem 0;
                display: none;
            }
            .progress-bar {
                height: 8px;
                background: #e2e8f0;
                border-radius: 4px;
                overflow: hidden;
                margin-top: 8px;
            }
            .progress-fill {
                height: 100%;
                background: var(--primary);
                width: 0%;
                transition: width 0.3s ease;
            }
            .progress-text {
                text-align: center;
                font-weight: 500;
                color: var(--dark);
                margin-top: 4px;
            }
            .loading {
                display: inline-block;
                width: 24px;
                height: 24px;
                border: 3px solid rgba(67, 97, 238, 0.3);
                border-radius: 50%;
                border-top-color: var(--primary);
                animation: spin 1s linear infinite;
            }
            @keyframes spin {
                to { transform: rotate(360deg); }
            }
            .instructions {
                background: #eef4ff;
                padding: 1.2rem;
                border-radius: 12px;
                margin: 1.2rem 0;
                border-left: 4px solid var(--primary);
            }
            .instructions ul {
                padding-left: 1.5rem;
                margin: 0.8rem 0;
            }
            .instructions li {
                margin-bottom: 0.5rem;
                line-height: 1.5;
            }
            .settings-container {
                background: #f0f7ff;
                padding: 1.2rem;
                border-radius: 12px;
                margin: 1.2rem 0;
                border: 1px solid #bfdbfe;
            }
            .settings-row {
                display: flex;
                align-items: center;
                justify-content: space-between;
                margin: 0.8rem 0;
            }
            .settings-label {
                font-weight: 500;
                color: var(--dark);
            }
            .settings-control {
                display: flex;
                align-items: center;
                gap: 8px;
            }
            input[type="range"] {
                width: 120px;
            }
            .value-display {
                min-width: 40px;
                text-align: center;
                font-weight: bold;
                color: var(--primary);
            }
            .voice-level-bar {
                height: 8px;
                background: #e2e8f0;
                border-radius: 4px;
                margin-top: 10px;
                overflow: hidden;
                position: relative;
            }
            .voice-level-fill {
                height: 100%;
                background: var(--success);
                width: 0%;
                transition: width 0.1s ease;
                border-radius: 4px;
            }
            .voice-level-fill.silent {
                background: var(--gray);
            }
            .stop-reason {
                font-size: 0.9rem;
                color: var(--warning);
                margin-top: 4px;
                text-align: center;
                font-style: italic;
            }
            .debug-log {
                font-family: monospace;
                font-size: 0.85rem;
                color: var(--gray);
                margin-top: 8px;
                max-height: 100px;
                overflow-y: auto;
                padding: 8px;
                background: #f8fafc;
                border-radius: 6px;
                border: 1px solid #e2e8f0;
                display: none;
            }
            .debug-log-entry {
                margin: 2px 0;
            }
            .debug-log-entry.error {
                color: var(--danger);
            }
            .upload-area {
                border: 2px dashed #cbd5e1;
                border-radius: 12px;
                padding: 2rem;
                text-align: center;
                margin: 1.5rem 0;
                background: #f8fafc;
                cursor: pointer;
                transition: all 0.3s ease;
            }
            .upload-area:hover {
                border-color: var(--primary);
                background: #eef4ff;
            }
            .upload-area.dragover {
                border-color: var(--primary);
                background: #dbeafe;
            }
            .file-info {
                margin-top: 1rem;
                text-align: left;
                padding: 0.8rem;
                background: white;
                border-radius: 8px;
                border: 1px solid #e2e8f0;
                display: none;
            }
            .file-name {
                font-weight: 500;
                color: var(--dark);
                word-break: break-all;
            }
            .file-size {
                font-size: 0.9rem;
                color: var(--gray);
            }
            .supported-formats {
                font-size: 0.9rem;
                color: var(--gray);
                margin-top: 0.5rem;
                font-style: italic;
            }
            .segment-list {
                margin-top: 1rem;
                border: 1px solid #e2e8f0;
                border-radius: 8px;
                padding: 1rem;
                max-height: 300px;
                overflow-y: auto;
                background: #f8fafc;
                display: none;
            }
            .segment-item {
                padding: 0.5rem;
                border-bottom: 1px solid #e2e8f0;
                cursor: pointer;
            }
            .segment-item:last-child {
                border-bottom: none;
            }
            .segment-item.active {
                background: #dbeafe;
                border-left: 3px solid var(--primary);
            }
            .segment-time {
                color: var(--gray);
                font-size: 0.9rem;
            }
            @media (max-width: 600px) {
                .container {
                    padding: 1rem;
                }
                h1 {
                    font-size: 1.7rem;
                }
                .btn {
                    padding: 12px;
                    font-size: 1rem;
                }
                .tab-container {
                    flex-direction: column;
                    border-bottom: none;
                }
                .tab {
                    width: 100%;
                    text-align: center;
                    border-bottom: 2px solid #e2e8f0 !important;
                }
                .tab.active {
                    border-bottom: 2px solid var(--primary) !important;
                }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¤ è¯­éŸ³è½¬æ–‡å­—</h1>
            
            <div class="tab-container">
                <div class="tab active" data-tab="record">éº¦å…‹é£å½•éŸ³</div>
                <div class="tab" data-tab="upload">ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶</div>
            </div>
            
            <div class="tab-content active" id="record-tab">
                <div class="instructions">
                    <p><strong>ä½¿ç”¨è¯´æ˜:</strong></p>
                    <ul>
                        <li>é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œæµè§ˆå™¨ä¼šè¯·æ±‚éº¦å…‹é£æƒé™ï¼Œè¯·ç‚¹å‡»"å…è®¸"</li>
                        <li>ç‚¹å‡»"å¼€å§‹å½•éŸ³"æŒ‰é’®å¼€å§‹å½•éŸ³ï¼Œå†ç‚¹å‡»ä¸€æ¬¡åœæ­¢å½•éŸ³</li>
                        <li>å½“æ£€æµ‹åˆ°æŒç»­é™éŸ³æ—¶ï¼Œå½•éŸ³ä¼šè‡ªåŠ¨åœæ­¢ï¼ˆå¯åœ¨ä¸‹æ–¹è®¾ç½®æ—¶é•¿ï¼‰</li>
                        <li>è½¬å½•ç»“æœä¼šæ˜¾ç¤ºåœ¨ä¸‹æ–¹åŒºåŸŸ</li>
                    </ul>
                </div>
                
                <div class="settings-container">
                    <div class="settings-row">
                        <span class="settings-label">é™éŸ³è¶…æ—¶åœæ­¢ (ç§’):</span>
                        <div class="settings-control">
                            <input type="range" id="silenceThreshold" min="1" max="10" value="2" step="1">
                            <span class="value-display" id="thresholdValue">2</span>
                        </div>
                    </div>
                    <div class="voice-level-bar">
                        <div class="voice-level-fill" id="voiceLevelFill"></div>
                    </div>
                    <div class="debug-log" id="debugLog"></div>
                </div>
                
                <div class="status-container">
                    <span id="statusIcon" class="loading"></span>
                    <span id="statusText">æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...</span>
                    <span id="recordingIndicator" class="recording-indicator"></span>
                </div>
                
                <div id="permissionMessage" class="permission-message">
                    âš ï¸ è¯·å…è®¸éº¦å…‹é£è®¿é—®æƒé™ï¼Œå¦åˆ™æ— æ³•å½•éŸ³
                </div>
                
                <button id="recordBtn" class="btn btn-record" disabled>
                    <span id="btnText">å¼€å§‹å½•éŸ³</span>
                </button>
                
                <div id="stopReason" class="stop-reason" style="display:none;"></div>
            </div>
            
            <div class="tab-content" id="upload-tab">
                <div class="instructions">
                    <p><strong>ä½¿ç”¨è¯´æ˜:</strong></p>
                    <ul>
                        <li>æ”¯æŒå¸¸è§éŸ³é¢‘æ ¼å¼ï¼šWAV, MP3, M4A, FLAC, OGG</li>
                        <li>æ–‡ä»¶å¤§å°é™åˆ¶ï¼š100MBä»¥å†…</li>
                        <li>ä¸Šä¼ é•¿éŸ³é¢‘ä¼šè‡ªåŠ¨åˆ†æ®µå¤„ç†ï¼Œæ¯æ®µå®Œæˆåå®æ—¶æ˜¾ç¤ºç»“æœ</li>
                        <li>ç‚¹å‡»ä¸‹æ–¹åŒºåŸŸé€‰æ‹©æ–‡ä»¶ï¼Œæˆ–ç›´æ¥æ‹–æ‹½æ–‡ä»¶åˆ°è¯¥åŒºåŸŸ</li>
                    </ul>
                </div>
                
                <div class="upload-area" id="uploadArea">
                    <div class="loading" id="uploadLoading" style="display:none;"></div>
                    <div id="uploadText">ğŸ“ ç‚¹å‡»ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ æˆ– æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„</div>
                    <div class="supported-formats">æ”¯æŒæ ¼å¼: WAV, MP3, M4A, FLAC, OGG (æœ€å¤§ 100MB)</div>
                </div>
                
                <div class="file-info" id="fileInfo">
                    <div class="file-name" id="fileName">æ–‡ä»¶å</div>
                    <div class="file-size" id="fileSize">0 KB</div>
                    <div class="file-duration" id="fileDuration" style="display:none; margin-top: 4px; font-size: 0.9rem; color: var(--primary);">æ—¶é•¿: 0:00</div>
                </div>
                
                <div class="segment-list" id="segmentList">
                    <!-- åˆ†æ®µåˆ—è¡¨å°†åœ¨è¿™é‡ŒåŠ¨æ€ç”Ÿæˆ -->
                </div>
                
                <div class="progress-container" id="progressContainer">
                    <div class="progress-bar">
                        <div class="progress-fill" id="progressFill"></div>
                    </div>
                    <div class="progress-text" id="progressText">0/0 æ®µ</div>
                </div>
                
                <button id="transcribeFileBtn" class="btn btn-upload" disabled>
                    <span id="transcribeFileBtnText">å¼€å§‹è½¬æ–‡å­—</span>
                </button>
                <button id="cancelBtn" class="btn btn-cancel" style="display:none;" disabled>
                    <span id="cancelBtnText">å–æ¶ˆå¤„ç†</span>
                </button>
            </div>
            
            <div id="transcript" class="transcript">è½¬å½•ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...</div>
            
            <div id="errorContainer" class="status-error" style="display:none;"></div>
        </div>

        <script>
            // å…¨å±€çŠ¶æ€å˜é‡
            let mediaRecorder = null;
            let audioContext = null;
            let analyser = null;
            let stream = null;
            let audioChunks = [];
            let silenceTimer = null;
            let isRecording = false;
            let lastSoundTime = 0;
            let currentSilenceTimeout = 2000; // é»˜è®¤2ç§’
            let rmsValues = []; // ç”¨äºå¹³æ»‘RMSå€¼
            let silenceDetectionInterval = null;
            let currentAudioFile = null;
            let isModelLoaded = false;
            let audioSegments = []; // å­˜å‚¨åˆ†æ®µä¿¡æ¯
            let currentSegmentIndex = 0;
            let isProcessingSegments = false;
            let processingStartTime = 0;
            let cancelRequested = false;
            let isInitializing = true; // æ–°å¢ï¼šåˆå§‹åŠ è½½çŠ¶æ€
            const audioContextCache = {}; // éŸ³é¢‘ä¸Šä¸‹æ–‡ç¼“å­˜
            
            // é…ç½®å‚æ•°
            const SILENCE_THRESHOLD = 0.02; // éŸ³é‡é˜ˆå€¼
            const SILENCE_CHECK_INTERVAL = 100; // æ£€æŸ¥é—´éš”(ms)
            const RMS_SMOOTHING = 5; // RMSå¹³æ»‘çª—å£å¤§å°
            const MAX_FILE_SIZE = 100 * 1024 * 1024; // 100MB
            const MAX_SEGMENT_DURATION = 30; // æœ€å¤§åˆ†æ®µæ—¶é•¿(ç§’)
            const MIN_SILENCE_DURATION = 0.5; // æœ€å°é™éŸ³æŒç»­æ—¶é—´(ç§’)ç”¨äºåˆ†æ®µ
            
            // DOMå…ƒç´ 
            const recordBtn = document.getElementById('recordBtn');
            const statusText = document.getElementById('statusText');
            const statusIcon = document.getElementById('statusIcon');
            const recordingIndicator = document.getElementById('recordingIndicator');
            const btnText = document.getElementById('btnText');
            const transcriptEl = document.getElementById('transcript');
            const permissionMessage = document.getElementById('permissionMessage');
            const errorContainer = document.getElementById('errorContainer');
            const silenceThresholdSlider = document.getElementById('silenceThreshold');
            const thresholdValueDisplay = document.getElementById('thresholdValue');
            const voiceLevelFill = document.getElementById('voiceLevelFill');
            const stopReasonEl = document.getElementById('stopReason');
            const debugLog = document.getElementById('debugLog');
            
            // æ–‡ä»¶ä¸Šä¼ ç›¸å…³å…ƒç´ 
            const uploadArea = document.getElementById('uploadArea');
            const uploadText = document.getElementById('uploadText');
            const uploadLoading = document.getElementById('uploadLoading');
            const fileInfo = document.getElementById('fileInfo');
            const fileNameEl = document.getElementById('fileName');
            const fileSizeEl = document.getElementById('fileSize');
            const fileDurationEl = document.getElementById('fileDuration');
            const transcribeFileBtn = document.getElementById('transcribeFileBtn');
            const transcribeFileBtnText = document.getElementById('transcribeFileBtnText');
            const cancelBtn = document.getElementById('cancelBtn');
            const cancelBtnText = document.getElementById('cancelBtnText');
            const progressContainer = document.getElementById('progressContainer');
            const progressFill = document.getElementById('progressFill');
            const progressText = document.getElementById('progressText');
            const segmentList = document.getElementById('segmentList');
            
            // é€‰é¡¹å¡
            const tabs = document.querySelectorAll('.tab');
            const tabContents = document.querySelectorAll('.tab-content');
            
            // åˆå§‹åŒ–
            document.addEventListener('DOMContentLoaded', async () => {
                logDebug('DOMContentLoaded äº‹ä»¶è§¦å‘ï¼Œå¼€å§‹åˆå§‹åŒ–');
                
                // æ£€æŸ¥å®‰å…¨ä¸Šä¸‹æ–‡
                if (!isSecureContext()) {
                    handleError('å¿…é¡»åœ¨å®‰å…¨ä¸Šä¸‹æ–‡(HTTPSæˆ–localhost)ä¸­ä½¿ç”¨');
                    return;
                }
                
                // è®¾ç½®é™éŸ³è¶…æ—¶æ»‘å—
                silenceThresholdSlider.addEventListener('input', function() {
                    currentSilenceTimeout = parseInt(this.value) * 1000;
                    thresholdValueDisplay.textContent = this.value;
                    logDebug(`é™éŸ³è¶…æ—¶è®¾ç½®ä¸º: ${this.value} ç§’`);
                });
                
                // æ£€æŸ¥æ¨¡å‹çŠ¶æ€
                await checkModelStatus();
                
                // æ·»åŠ æŒ‰é’®ç‚¹å‡»äº‹ä»¶
                recordBtn.addEventListener('click', toggleRecording);
                cancelBtn.addEventListener('click', cancelProcessing);
                
                // æ–‡ä»¶ä¸Šä¼ äº‹ä»¶
                setupFileUpload();
                
                // é€‰é¡¹å¡åˆ‡æ¢
                setupTabs();
            });
            
            function setupTabs() {
                tabs.forEach(tab => {
                    tab.addEventListener('click', () => {
                        const tabName = tab.getAttribute('data-tab');
                        
                        // æ›´æ–°é€‰é¡¹å¡çŠ¶æ€
                        tabs.forEach(t => t.classList.remove('active'));
                        tab.classList.add('active');
                        
                        // æ˜¾ç¤ºå¯¹åº”å†…å®¹
                        tabContents.forEach(content => content.classList.remove('active'));
                        document.getElementById(`${tabName}-tab`).classList.add('active');
                        
                        // å¦‚æœåˆ‡æ¢åˆ°ä¸Šä¼ æ ‡ç­¾ä¸”æœ‰æ–‡ä»¶ï¼Œå¯ç”¨æŒ‰é’®
                        if (tabName === 'upload' && currentAudioFile) {
                            transcribeFileBtn.disabled = false;
                        }
                    });
                });
            }
            
            function setupFileUpload() {
                // ç‚¹å‡»ä¸Šä¼ åŒºåŸŸ
                uploadArea.addEventListener('click', () => {
                    const fileInput = document.createElement('input');
                    fileInput.type = 'file';
                    fileInput.accept = 'audio/*, .wav, .mp3, .m4a, .flac, .ogg';
                    fileInput.onchange = (e) => {
                        handleFileSelect(e.target.files[0]);
                        fileInput.remove();
                    };
                    fileInput.click();
                });
                
                // æ‹–æ‹½æ”¯æŒ
                uploadArea.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadArea.classList.add('dragover');
                });
                
                uploadArea.addEventListener('dragleave', () => {
                    uploadArea.classList.remove('dragover');
                });
                
                uploadArea.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadArea.classList.remove('dragover');
                    
                    if (e.dataTransfer.files.length > 0) {
                        handleFileSelect(e.dataTransfer.files[0]);
                    }
                });
                
                // è½¬æ–‡å­—æŒ‰é’®
                transcribeFileBtn.addEventListener('click', startTranscription);
            }
            
            function handleFileSelect(file) {
                if (!file) return;
                
                // æ£€æŸ¥æ–‡ä»¶å¤§å°
                if (file.size > MAX_FILE_SIZE) {
                    handleError(`æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ (æœ€å¤§ 100MB)ï¼Œå½“å‰å¤§å°: ${formatFileSize(file.size)}`);
                    return;
                }
                
                // æ£€æŸ¥æ–‡ä»¶ç±»å‹
                const validTypes = ['audio/wav', 'audio/mp3', 'audio/mpeg', 'audio/x-m4a', 'audio/mp4', 'audio/flac', 'audio/ogg', 'audio/webm'];
                const fileExt = file.name.split('.').pop().toLowerCase();
                const validExts = ['wav', 'mp3', 'm4a', 'flac', 'ogg', 'webm'];
                
                if (!validTypes.includes(file.type) && !validExts.includes(fileExt)) {
                    handleError(`ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: ${file.type || fileExt}ã€‚è¯·ä¸Šä¼ WAV, MP3, M4A, FLACæˆ–OGGæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶`);
                    return;
                }
                
                currentAudioFile = file;
                displayFileInfo(file);
                transcribeFileBtn.disabled = false;
                logDebug(`é€‰æ‹©äº†æ–‡ä»¶: ${file.name}, å¤§å°: ${formatFileSize(file.size)}, ç±»å‹: ${file.type}`);
                
                // é‡ç½®åˆ†æ®µä¿¡æ¯
                audioSegments = [];
                segmentList.style.display = 'none';
                segmentList.innerHTML = '';
                progressContainer.style.display = 'none';
                cancelRequested = false;
                
                // åˆ†æéŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿
                analyzeAudioDuration(file);
            }
            
            function displayFileInfo(file) {
                fileNameEl.textContent = file.name;
                fileSizeEl.textContent = formatFileSize(file.size);
                fileInfo.style.display = 'block';
            }
            
            function formatFileSize(bytes) {
                if (bytes === 0) return '0 Bytes';
                const k = 1024;
                const sizes = ['Bytes', 'KB', 'MB', 'GB'];
                const i = Math.floor(Math.log(bytes) / Math.log(k));
                return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
            }
            
            function formatTime(seconds) {
                const mins = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${mins}:${secs.toString().padStart(2, '0')}`;
            }
            
            async function analyzeAudioDuration(file) {
                try {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const arrayBuffer = await file.arrayBuffer();
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    const duration = audioBuffer.duration;
                    
                    fileDurationEl.textContent = `æ—¶é•¿: ${formatTime(duration)}`;
                    fileDurationEl.style.display = 'block';
                    
                    // å¦‚æœéŸ³é¢‘è¾ƒé•¿ï¼Œæ˜¾ç¤ºé¢„ä¼°åˆ†æ®µä¿¡æ¯
                    if (duration > MAX_SEGMENT_DURATION * 1.5) {
                        const estimatedSegments = Math.ceil(duration / MAX_SEGMENT_DURATION);
                        statusText.innerHTML = `âœ… æ¨¡å‹å·²å°±ç»ªï¼Œæ£€æµ‹åˆ°é•¿éŸ³é¢‘(${formatTime(duration)})ï¼Œå°†è‡ªåŠ¨åˆ†æ®µå¤„ç† (é¢„è®¡ ${estimatedSegments} æ®µ)`;
                    }
                    
                    audioContext.close();
                } catch (error) {
                    logDebug(`åˆ†æéŸ³é¢‘æ—¶é•¿å¤±è´¥: ${error.message}`, true);
                }
            }
            
            async function startTranscription() {
                if (!currentAudioFile) {
                    handleError('æ²¡æœ‰é€‰æ‹©éŸ³é¢‘æ–‡ä»¶');
                    return;
                }
                
                if (!isModelLoaded) {
                    handleError('æ¨¡å‹å°šæœªåŠ è½½å®Œæˆï¼Œè¯·ç¨å€™...');
                    return;
                }
                
                // é‡ç½®UI
                transcriptEl.innerHTML = '<div class="loading"></div> åˆ†æéŸ³é¢‘å¹¶åˆ›å»ºåˆ†æ®µ...';
                transcriptEl.classList.add('processing');
                transcribeFileBtn.disabled = true;
                cancelBtn.style.display = 'block';
                cancelBtn.disabled = false;
                progressContainer.style.display = 'block';
                progressFill.style.width = '0%';
                progressText.textContent = '0/0 æ®µ';
                
                try {
                    // åˆ†æéŸ³é¢‘å¹¶åˆ›å»ºåˆ†æ®µ
                    logDebug(`å¼€å§‹åˆ†æéŸ³é¢‘åˆ†æ®µ: ${currentAudioFile.name}`);
                    audioSegments = await analyzeAudioSegments(currentAudioFile);
                    
                    if (audioSegments.length === 0) {
                        throw new Error('æ— æ³•åˆ›å»ºæœ‰æ•ˆçš„éŸ³é¢‘åˆ†æ®µï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶');
                    }
                    
                    logDebug(`æˆåŠŸåˆ›å»º ${audioSegments.length} ä¸ªåˆ†æ®µ`);
                    displaySegments(audioSegments);
                    
                    // å¼€å§‹åˆ†æ®µå¤„ç†
                    isProcessingSegments = true;
                    processingStartTime = Date.now();
                    currentSegmentIndex = 0;
                    cancelRequested = false;
                    
                    // æ›´æ–°è¿›åº¦
                    updateProgress(0, audioSegments.length);
                    
                    // å¤„ç†ç¬¬ä¸€ä¸ªåˆ†æ®µ
                    await processNextSegment();
                    
                } catch (error) {
                    logDebug(`å‡†å¤‡å¤„ç†å¤±è´¥: ${error.message}`, true);
                    handleError(`å‡†å¤‡å¤±è´¥: ${error.message}`);
                    resetProcessingUI();
                }
            }
            
            async function analyzeAudioSegments(file) {
                return new Promise((resolve, reject) => {
                    // åˆ›å»ºä¸´æ—¶URL
                    const objectURL = URL.createObjectURL(file);
                    
                    // åˆ›å»ºéŸ³é¢‘å…ƒç´ 
                    const audio = new Audio();
                    audio.src = objectURL;
                    
                    audio.onloadedmetadata = async () => {
                        const duration = audio.duration;
                        logDebug(`éŸ³é¢‘æ€»æ—¶é•¿: ${duration.toFixed(2)} ç§’`);
                        
                        if (duration <= MAX_SEGMENT_DURATION) {
                            // çŸ­éŸ³é¢‘ï¼Œä¸åˆ†æ®µ
                            const segments = [{
                                start: 0,
                                end: duration,
                                blob: file,
                                index: 0
                            }];
                            URL.revokeObjectURL(objectURL);
                            resolve(segments);
                            return;
                        }
                        
                        // é•¿éŸ³é¢‘ï¼Œéœ€è¦åˆ†æ®µ
                        logDebug('å¼€å§‹åˆ†æé™éŸ³ç‚¹ä»¥åˆ›å»ºåˆ†æ®µ...');
                        
                        try {
                            // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
                            const AudioContext = window.AudioContext || window.webkitAudioContext;
                            const audioContext = new AudioContext({ sampleRate: 16000 });
                            
                            // è·å–éŸ³é¢‘æ•°æ®
                            const response = await fetch(objectURL);
                            const arrayBuffer = await response.arrayBuffer();
                            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                            
                            // åˆ†æé™éŸ³ç‚¹
                            const silencePoints = detectSilencePoints(audioBuffer);
                            logDebug(`æ£€æµ‹åˆ° ${silencePoints.length} ä¸ªé™éŸ³ç‚¹`);
                            
                            // åˆ›å»ºåˆ†æ®µ
                            const segments = createSegmentsFromSilencePoints(silencePoints, audioBuffer.duration, file);
                            
                            // æ¸…ç†
                            URL.revokeObjectURL(objectURL);
                            audioContext.close();
                            
                            logDebug(`åˆ›å»ºäº† ${segments.length} ä¸ªåˆ†æ®µ`);
                            resolve(segments);
                        } catch (error) {
                            URL.revokeObjectURL(objectURL);
                            reject(error);
                        }
                    };
                    
                    audio.onerror = (e) => {
                        URL.revokeObjectURL(objectURL);
                        reject(new Error('æ— æ³•åŠ è½½éŸ³é¢‘æ–‡ä»¶'));
                    };
                });
            }
            
            function detectSilencePoints(audioBuffer) {
                const channelData = audioBuffer.getChannelData(0);
                const sampleRate = audioBuffer.sampleRate;
                const frameSize = 1024;
                const silencePoints = [];
                let inSilence = false;
                let silenceStart = 0;
                
                for (let i = 0; i < channelData.length; i += frameSize) {
                    const frame = channelData.slice(i, Math.min(i + frameSize, channelData.length));
                    const rms = calculateRMS(frame);
                    
                    const time = i / sampleRate;
                    
                    if (rms < SILENCE_THRESHOLD) {
                        if (!inSilence) {
                            inSilence = true;
                            silenceStart = time;
                        }
                    } else {
                        if (inSilence) {
                            const silenceDuration = time - silenceStart;
                            if (silenceDuration >= MIN_SILENCE_DURATION) {
                                silencePoints.push({
                                    time: silenceStart,
                                    duration: silenceDuration
                                });
                            }
                            inSilence = false;
                        }
                    }
                }
                
                // æ£€æŸ¥æœ€åæ˜¯å¦åœ¨é™éŸ³ä¸­
                if (inSilence) {
                    const silenceDuration = audioBuffer.duration - silenceStart;
                    if (silenceDuration >= MIN_SILENCE_DURATION) {
                        silencePoints.push({
                            time: silenceStart,
                            duration: silenceDuration
                        });
                    }
                }
                
                return silencePoints;
            }
            
            function calculateRMS(buffer) {
                let sum = 0;
                for (let i = 0; i < buffer.length; i++) {
                    sum += buffer[i] * buffer[i];
                }
                return Math.sqrt(sum / buffer.length);
            }
            
            function createSegmentsFromSilencePoints(silencePoints, totalDuration, originalFile) {
                const segments = [];
                let currentStart = 0;
                let segmentIndex = 0;
                
                // æŒ‰æ—¶é—´æ’åº
                silencePoints.sort((a, b) => a.time - b.time);
                
                // åˆ›å»ºåˆ†æ®µ
                for (const point of silencePoints) {
                    const segmentDuration = point.time - currentStart;
                    
                    // å¦‚æœåˆ†æ®µå¤ªçŸ­ï¼Œåˆå¹¶åˆ°ä¸‹ä¸€æ®µ
                    if (segmentDuration < 2) continue;
                    
                    // åˆ›å»ºä¸€ä¸ªåˆ†æ®µ
                    segments.push({
                        start: currentStart,
                        end: point.time,
                        originalFile: originalFile,
                        index: segmentIndex++
                    });
                    currentStart = point.time;
                }
                
                // å¤„ç†æœ€åä¸€æ®µ
                const lastDuration = totalDuration - currentStart;
                if (lastDuration > 1) { // å¿½ç•¥å¤ªçŸ­çš„æœ€åä¸€æ®µ
                    segments.push({
                        start: currentStart,
                        end: totalDuration,
                        originalFile: originalFile,
                        index: segmentIndex++
                    });
                }
                
                // å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é™éŸ³ç‚¹ï¼ŒæŒ‰å›ºå®šæ—¶é•¿åˆ†æ®µ
                if (segments.length === 0) {
                    let start = 0;
                    let index = 0;
                    while (start < totalDuration) {
                        const end = Math.min(start + MAX_SEGMENT_DURATION, totalDuration);
                        segments.push({
                            start: start,
                            end: end,
                            originalFile: originalFile,
                            index: index++
                        });
                        start = end;
                    }
                }
                
                return segments;
            }
            
            function displaySegments(segments) {
                segmentList.innerHTML = '';
                segmentList.style.display = 'block';
                
                segments.forEach((segment, index) => {
                    const segmentEl = document.createElement('div');
                    segmentEl.className = 'segment-item';
                    segmentEl.dataset.index = index;
                    segmentEl.innerHTML = `
                        <div>æ®µè½ ${index + 1}</div>
                        <div class="segment-time">${formatTime(segment.start)} - ${formatTime(segment.end)}</div>
                    `;
                    segmentList.appendChild(segmentEl);
                    
                    // ç‚¹å‡»æ®µè½è·³è½¬
                    segmentEl.addEventListener('click', () => {
                        // é«˜äº®é€‰ä¸­æ®µè½
                        document.querySelectorAll('.segment-item').forEach(el => {
                            el.classList.remove('active');
                        });
                        segmentEl.classList.add('active');
                        
                        // æ»šåŠ¨åˆ°æ®µè½
                        segmentEl.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                    });
                });
            }
            
            async function processNextSegment() {
                if (cancelRequested) {
                    logDebug('å¤„ç†å·²å–æ¶ˆ');
                    resetProcessingUI();
                    return;
                }
                
                if (currentSegmentIndex >= audioSegments.length) {
                    // æ‰€æœ‰åˆ†æ®µå¤„ç†å®Œæˆ
                    logDebug('æ‰€æœ‰åˆ†æ®µå¤„ç†å®Œæˆ');
                    finishProcessing();
                    return;
                }
                
                const segment = audioSegments[currentSegmentIndex];
                const segmentNumber = currentSegmentIndex + 1;
                
                // é«˜äº®å½“å‰æ®µè½
                document.querySelectorAll('.segment-item').forEach(el => {
                    el.classList.remove('active');
                });
                document.querySelector(`.segment-item[data-index="${currentSegmentIndex}"]`)?.classList.add('active');
                
                // æ›´æ–°è¿›åº¦
                updateProgress(currentSegmentIndex, audioSegments.length);
                logDebug(`å¼€å§‹å¤„ç†åˆ†æ®µ ${segmentNumber}/${audioSegments.length}: ${formatTime(segment.start)} - ${formatTime(segment.end)}`);
                
                try {
                    // åˆ›å»ºåˆ†æ®µBlob
                    const segmentBlob = await createSegmentBlob(segment);
                    
                    // ä¼ å…¥å®Œæ•´çš„segmentå¯¹è±¡
                    const result = await transcribeAudioSegment(segmentBlob, segmentNumber, segment);
                    
                    // æ˜¾ç¤ºç»“æœ
                    displayPartialResult(result, segment);
                    
                    // æ›´æ–°è¿›åº¦
                    currentSegmentIndex++;
                    updateProgress(currentSegmentIndex, audioSegments.length);
                    
                    // ç»§ç»­å¤„ç†ä¸‹ä¸€æ®µ
                    setTimeout(processNextSegment, 100); // çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…é˜»å¡UI
                    
                } catch (error) {
                    logDebug(`å¤„ç†åˆ†æ®µ ${segmentNumber} å¤±è´¥: ${error.message}`, true);
                    handleError(`åˆ†æ®µ ${segmentNumber} å¤„ç†å¤±è´¥: ${error.message}`);
                    
                    // è·³è¿‡å½“å‰åˆ†æ®µï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æ®µ
                    currentSegmentIndex++;
                    setTimeout(processNextSegment, 100);
                }
            }
            
            async function createSegmentBlob(segment) {
                // ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦åœ¨åç«¯è¿›è¡Œç²¾ç¡®åˆ†æ®µ
                return segment.originalFile;
            }
            
            async function transcribeAudioSegment(audioBlob, segmentNumber, segment) {
                const formData = new FormData();
                formData.append('audio', audioBlob, `segment_${segment.index}.wav`);
                formData.append('source', 'file_segment');
                formData.append('segment_index', segment.index);
                formData.append('total_segments', audioSegments.length);
                formData.append('start_time', segment.start);
                formData.append('end_time', segment.end);
                
                const response = await fetch('/transcribe-segment', {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                
                if (!response.ok) {
                    throw new Error(result.error || `æœåŠ¡å™¨é”™è¯¯: ${response.status}`);
                }
                
                return {
                    text: result.text || '[æœªè¯†åˆ«åˆ°å†…å®¹]',
                    segmentIndex: segment.index,
                    timestamp: new Date().toISOString()
                };
            }
            
            function displayPartialResult(result, segment) {
                // åˆ›å»ºåˆ†æ®µæ ‡è®°
                const marker = document.createElement('div');
                marker.className = 'segment-marker';
                marker.textContent = `#${result.segmentIndex + 1}`;
                
                // æ›´æ–°è½¬å½•æ–‡æœ¬
                let currentText = transcriptEl.textContent.trim();
                if (currentText === 'è½¬å½•ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...' || currentText.startsWith('åˆ†æéŸ³é¢‘')) {
                    currentText = '';
                }
                
                // ä¿®å¤ï¼šä½¿ç”¨HTMLä¿ç•™æ¢è¡Œ
                const separator = currentText ? '\\n\\n' : '';
                const newContent = `${currentText}${separator}[${formatTime(segment.start)}-${formatTime(segment.end)}] ${result.text}`;
                
                // ä¿ç•™ç°æœ‰çš„HTMLå†…å®¹
                const tempDiv = document.createElement('div');
                tempDiv.textContent = newContent;
                const newHTMLContent = tempDiv.innerHTML;
                
                transcriptEl.innerHTML = newHTMLContent;
                transcriptEl.appendChild(marker);
                
                // æ»šåŠ¨åˆ°åº•éƒ¨
                transcriptEl.scrollTop = transcriptEl.scrollHeight;
            }
            
            function updateProgress(current, total) {
                const progress = (current / total) * 100;
                progressFill.style.width = `${progress}%`;
                progressText.textContent = `${current}/${total} æ®µ`;
                
                // ä¼°ç®—å‰©ä½™æ—¶é—´
                if (current > 0 && processingStartTime) {
                    const elapsed = Date.now() - processingStartTime;
                    const avgTimePerSegment = elapsed / current;
                    const remaining = (total - current) * avgTimePerSegment;
                    const remainingText = remaining > 60000 ? 
                        `çº¦ ${(remaining / 60000).toFixed(1)} åˆ†é’Ÿ` : 
                        `çº¦ ${(remaining / 1000).toFixed(0)} ç§’`;
                    
                    progressText.textContent += ` | ${remainingText}`;
                }
            }
            
            function finishProcessing() {
                transcriptEl.classList.remove('processing');
                const totalTime = (Date.now() - processingStartTime) / 1000;
                const finalContent = transcriptEl.textContent + `\\n\\nâœ… è½¬å½•å®Œæˆï¼æ€»è€—æ—¶: ${totalTime.toFixed(1)} ç§’, å…± ${audioSegments.length} æ®µ`;
                
                // ä¿ç•™HTMLæ ¼å¼
                const tempDiv = document.createElement('div');
                tempDiv.textContent = finalContent;
                transcriptEl.innerHTML = tempDiv.innerHTML;
                
                resetProcessingUI();
                logDebug(`è½¬å½•å®Œæˆï¼Œæ€»è€—æ—¶: ${totalTime.toFixed(1)} ç§’`);
            }
            
            function cancelProcessing() {
                cancelRequested = true;
                cancelBtn.disabled = true;
                cancelBtnText.textContent = 'æ­£åœ¨å–æ¶ˆ...';
                logDebug('ç”¨æˆ·è¯·æ±‚å–æ¶ˆå¤„ç†');
            }
            
            function resetProcessingUI() {
                isProcessingSegments = false;
                transcribeFileBtn.disabled = false;
                transcribeFileBtnText.textContent = 'å¼€å§‹è½¬æ–‡å­—';
                cancelBtn.style.display = 'none';
                progressContainer.style.display = 'none';
                processingStartTime = 0;
            }
            
            function isSecureContext() {
                return window.isSecureContext || 
                       window.location.hostname === 'localhost' || 
                       window.location.hostname === '127.0.0.1';
            }
            
            function logDebug(message, isError = false) {
                const now = new Date().toLocaleTimeString();
                const entry = document.createElement('div');
                entry.className = `debug-log-entry ${isError ? 'error' : ''}`;
                entry.textContent = `[${now}] ${message}`;
                debugLog.appendChild(entry);
                debugLog.scrollTop = debugLog.scrollHeight;
                debugLog.style.display = 'block';
                
                if (isError) {
                    console.error(message);
                } else {
                    console.log(message);
                }
            }
            
            function handleError(message) {
                console.error('é”™è¯¯:', message);
                errorContainer.textContent = message;
                errorContainer.style.display = 'block';
                statusText.textContent = 'âŒ å‘ç”Ÿé”™è¯¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹è¯¦æƒ…';
                statusIcon.style.display = 'none';
                logDebug(message, true);
            }
            
            async function checkModelStatus() {
                try {
                    logDebug('æ£€æŸ¥æ¨¡å‹çŠ¶æ€...');
                    const response = await fetch('/model-status', { cache: 'no-cache' });
                    const data = await response.json();
                    
                    if (data.error) {
                        handleError(data.error);
                        return;
                    }
                    
                    if (data.loaded) {
                        statusIcon.style.display = 'none';
                        statusText.innerHTML = 'âœ… æ¨¡å‹å·²å°±ç»ªï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å½•éŸ³';
                        recordBtn.disabled = false;
                        isModelLoaded = true;
                        
                        // æ›´æ–°ç•Œé¢çŠ¶æ€
                        isInitializing = false;
                        
                        logDebug('æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå¯ç”¨å½•éŸ³æŒ‰é’®');
                    } else {
                        logDebug('æ¨¡å‹å°šæœªåŠ è½½å®Œæˆï¼Œ500msåé‡è¯•');
                        setTimeout(checkModelStatus, 500);
                    }
                } catch (error) {
                    handleError('æ£€æŸ¥æ¨¡å‹çŠ¶æ€å¤±è´¥: ' + error.message);
                }
            }
            
            async function toggleRecording() {
                if (recordBtn.disabled) {
                    logDebug('æŒ‰é’®è¢«ç¦ç”¨ï¼Œæ— æ³•æ“ä½œ');
                    return;
                }
                
                recordBtn.disabled = true;
                logDebug(`åˆ‡æ¢å½•éŸ³çŠ¶æ€: å½“å‰çŠ¶æ€ = ${isRecording ? 'å½•éŸ³ä¸­' : 'åœæ­¢'}`);
                
                try {
                    if (!isRecording) {
                        // å¼€å§‹å½•éŸ³
                        await startRecording();
                    } else {
                        // åœæ­¢å½•éŸ³
                        stopRecording('manual');
                    }
                } catch (error) {
                    handleError('å½•éŸ³æ“ä½œå¤±è´¥: ' + error.message);
                    resetUI();
                }
            }
            
            async function startRecording() {
                logDebug('===== å¼€å§‹å½•éŸ³æµç¨‹ =====');
                
                // 1. è¯·æ±‚éº¦å…‹é£æƒé™
                logDebug('[æ­¥éª¤1] è¯·æ±‚éº¦å…‹é£æƒé™...');
                const hasPermission = await requestMicrophonePermission();
                if (!hasPermission) {
                    logDebug('éº¦å…‹é£æƒé™è¢«æ‹’ç»');
                    resetUI();
                    return;
                }
                logDebug('[æ­¥éª¤1] éº¦å…‹é£æƒé™è·å–æˆåŠŸ');
                
                // 2. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡ (ä½†ä¸å¯åŠ¨é™éŸ³æ£€æµ‹)
                logDebug('[æ­¥éª¤2] åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡...');
                if (!initAudioContext()) {
                    logDebug('éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥');
                    resetUI();
                    return;
                }
                logDebug('[æ­¥éª¤2] éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–æˆåŠŸ');
                
                // 3. è®¾ç½®å½•éŸ³
                logDebug('[æ­¥éª¤3] è®¾ç½®MediaRecorder...');
                setupMediaRecorder();
                logDebug('[æ­¥éª¤3] MediaRecorderè®¾ç½®å®Œæˆ');
                
                // 4. å¼€å§‹å½•éŸ³
                logDebug('[æ­¥éª¤4] å¼€å§‹å½•éŸ³');
                mediaRecorder.start();
                
                // 5. è®¾ç½®å½•éŸ³çŠ¶æ€
                isRecording = true;
                lastSoundTime = Date.now(); // é‡ç½®æœ€åæœ‰å£°æ—¶é—´
                rmsValues = []; // é‡ç½®RMSå€¼
                
                // 6. ç°åœ¨æ‰å¯åŠ¨é™éŸ³æ£€æµ‹ï¼
                logDebug('[æ­¥éª¤5] å¯åŠ¨é™éŸ³æ£€æµ‹ (å½•éŸ³å·²å¼€å§‹)');
                startSilenceDetection();
                
                // 7. æ›´æ–°UI
                recordingIndicator.classList.add('active');
                btnText.textContent = 'åœæ­¢å½•éŸ³';
                recordBtn.classList.add('recording');
                stopReasonEl.style.display = 'none';
                recordBtn.disabled = false;
                
                logDebug('===== å½•éŸ³å·²æˆåŠŸå¯åŠ¨ =====');
            }
            
            async function requestMicrophonePermission() {
                try {
                    logDebug('å°è¯•è·å–éº¦å…‹é£æµ');
                    stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });
                    
                    logDebug('æˆåŠŸè·å–éº¦å…‹é£æµ');
                    permissionMessage.style.display = 'none';
                    return true;
                } catch (err) {
                    logDebug(`éº¦å…‹é£æƒé™é”™è¯¯: ${err.name} - ${err.message}`, true);
                    
                    let errorMessage = 'éº¦å…‹é£è®¿é—®é”™è¯¯: ';
                    if (err.name === 'NotAllowedError') {
                        errorMessage += 'æƒé™è¢«æ‹’ç»ã€‚è¯·åˆ·æ–°é¡µé¢å¹¶å…è®¸éº¦å…‹é£è®¿é—®';
                    } else if (err.name === 'NotFoundError') {
                        errorMessage += 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·æ£€æŸ¥è®¾å¤‡è¿æ¥';
                    } else if (err.name === 'NotReadableError') {
                        errorMessage += 'éº¦å…‹é£è¢«å…¶ä»–åº”ç”¨å ç”¨';
                    } else {
                        errorMessage += err.message || err.toString();
                    }
                    
                    permissionMessage.innerHTML = `âš ï¸ ${errorMessage}`;
                    permissionMessage.style.display = 'block';
                    return false;
                }
            }
            
            function initAudioContext() {
                try {
                    // å…³é—­ç°æœ‰ä¸Šä¸‹æ–‡
                    if (audioContext) {
                        audioContext.close();
                    }
                    
                    // åˆ›å»ºæ–°çš„éŸ³é¢‘ä¸Šä¸‹æ–‡
                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    audioContext = new AudioContext({ sampleRate: 16000 });
                    logDebug(`éŸ³é¢‘ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸï¼Œé‡‡æ ·ç‡: ${audioContext.sampleRate}Hz`);
                    
                    // åˆ›å»ºåˆ†æèŠ‚ç‚¹
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;
                    analyser.smoothingTimeConstant = 0.8; // å¹³æ»‘å¤„ç†
                    
                    // è¿æ¥éŸ³é¢‘æº
                    const source = audioContext.createMediaStreamSource(stream);
                    source.connect(analyser);
                    
                    // æ³¨æ„ï¼šè¿™é‡Œä¸å¯åŠ¨é™éŸ³æ£€æµ‹ï¼ä¼šåœ¨å½•éŸ³å¼€å§‹åå¯åŠ¨
                    return true;
                } catch (err) {
                    logDebug(`éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: ${err.message}`, true);
                    return false;
                }
            }
            
            function setupMediaRecorder() {
                // æ¸…ç©ºä¹‹å‰çš„å½•éŸ³æ•°æ®
                audioChunks = [];
                
                try {
                    // ä½¿ç”¨å…¼å®¹æ€§æ›´å¥½çš„MIMEç±»å‹
                    const mimeType = 'audio/webm';
                    
                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: mimeType,
                        audioBitsPerSecond: 128000
                    });
                    
                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                            logDebug(`æ”¶åˆ°éŸ³é¢‘æ•°æ®å—ï¼Œå¤§å°: ${event.data.size} bytes`);
                        }
                    };
                    
                    mediaRecorder.onstop = handleRecordingStop;
                    
                    mediaRecorder.onerror = (event) => {
                        logDebug(`MediaRecorderé”™è¯¯: ${event.error}`, true);
                        handleError(`å½•éŸ³é”™è¯¯: ${event.error}`);
                    };
                    
                    logDebug('MediaRecorderè®¾ç½®å®Œæˆ');
                } catch (err) {
                    logDebug(`MediaRecorderåˆå§‹åŒ–å¤±è´¥: ${err.message}`, true);
                    throw err;
                }
            }
            
            function startSilenceDetection() {
                if (silenceDetectionInterval) {
                    clearInterval(silenceDetectionInterval);
                }
                
                logDebug('>>>>> é™éŸ³æ£€æµ‹å·²å¯åŠ¨ <<<<<');
                
                // ä½¿ç”¨setIntervalç¡®ä¿å®šæœŸæ£€æŸ¥
                silenceDetectionInterval = setInterval(checkSilence, SILENCE_CHECK_INTERVAL);
            }
            
            function checkSilence() {
                // å…³é”®ï¼šåªåœ¨å½•éŸ³ä¸­ä¸”æœ‰åˆ†æå™¨æ—¶è¿›è¡Œæ£€æµ‹
                if (!isRecording || !analyser) {
                    logDebug('é™éŸ³æ£€æµ‹æ¡ä»¶ä¸æ»¡è¶³: isRecording=' + isRecording + ', analyser=' + !!analyser);
                    return;
                }
                
                try {
                    // è·å–éŸ³é¢‘æ•°æ®
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Float32Array(bufferLength);
                    analyser.getFloatTimeDomainData(dataArray);
                    
                    // è®¡ç®—RMSï¼ˆå‡æ–¹æ ¹ï¼‰å€¼
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i] * dataArray[i];
                    }
                    const rms = Math.sqrt(sum / bufferLength);
                    
                    // å¹³æ»‘RMSå€¼
                    rmsValues.push(rms);
                    if (rmsValues.length > RMS_SMOOTHING) {
                        rmsValues.shift();
                    }
                    const smoothedRms = rmsValues.reduce((a, b) => a + b, 0) / rmsValues.length;
                    
                    // æ›´æ–°éŸ³é‡æŒ‡ç¤ºæ¡
                    const volumePercent = Math.min(100, smoothedRms * 5000); // è°ƒæ•´ç³»æ•°æé«˜çµæ•åº¦
                    voiceLevelFill.style.width = `${volumePercent}%`;
                    voiceLevelFill.className = 'voice-level-fill ' + (smoothedRms < SILENCE_THRESHOLD ? 'silent' : '');
                    
                    // è°ƒè¯•è¾“å‡ºå…³é”®å€¼
                    if (rmsValues.length % 5 === 0) {
                        logDebug(`ğŸ¤ RMS: ${smoothedRms.toFixed(5)}, é˜ˆå€¼: ${SILENCE_THRESHOLD}, éŸ³é‡: ${volumePercent.toFixed(1)}%`);
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦é™éŸ³
                    if (smoothedRms < SILENCE_THRESHOLD) {
                        const silentDuration = Date.now() - lastSoundTime;
                        // logDebug(`ğŸ”‡ é™éŸ³ä¸­... æŒç»­æ—¶é—´: ${silentDuration}ms`);
                        
                        // å¦‚æœå·²ç»è¶…è¿‡é™éŸ³è¶…æ—¶æ—¶é—´
                        if (silentDuration > currentSilenceTimeout) {
                            logDebug(`â¹ï¸ æ£€æµ‹åˆ°æŒç»­é™éŸ³ ${silentDuration}msï¼Œè¶…è¿‡é˜ˆå€¼ ${currentSilenceTimeout}msï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³`);
                            stopReasonEl.textContent = `æ£€æµ‹åˆ°æŒç»­é™éŸ³ï¼ˆ${currentSilenceTimeout/1000}ç§’ï¼‰ï¼Œè‡ªåŠ¨åœæ­¢`;
                            stopReasonEl.style.display = 'block';
                            stopRecording('silence');
                            return;
                        }
                    } else {
                        // æœ‰å£°éŸ³ï¼Œæ›´æ–°æœ€åæœ‰å£°æ—¶é—´
                        lastSoundTime = Date.now();
                        // logDebug(`ğŸ”Š æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¹³æ»‘RMS: ${smoothedRms.toFixed(5)}`);
                    }
                    
                } catch (err) {
                    logDebug(`é™éŸ³æ£€æµ‹é”™è¯¯: ${err.message}`, true);
                }
            }
            
            function stopRecording(reason = 'manual') {
                logDebug(`â¹ï¸ åœæ­¢å½•éŸ³ï¼ŒåŸå› : ${reason}`);
                
                // åœæ­¢é™éŸ³æ£€æµ‹
                if (silenceDetectionInterval) {
                    clearInterval(silenceDetectionInterval);
                    silenceDetectionInterval = null;
                    logDebug('ğŸ”‡ é™éŸ³æ£€æµ‹å·²åœæ­¢');
                }
                
                // åœæ­¢MediaRecorder
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                    logDebug('âºï¸ MediaRecorderå·²åœæ­¢');
                }
                
                // æ¸…ç†èµ„æº
                if (stream) {
                    stream.getTracks().forEach(track => {
                        track.stop();
                        logDebug(`â¹ï¸ éŸ³è½¨å·²åœæ­¢: ${track.label}`);
                    });
                    stream = null;
                }
                
                if (audioContext) {
                    audioContext.close().then(() => {
                        logDebug('ğŸ”Š éŸ³é¢‘ä¸Šä¸‹æ–‡å·²å…³é—­');
                    }).catch(err => {
                        logDebug(`âŒ å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡é”™è¯¯: ${err.message}`, true);
                    });
                    audioContext = null;
                    analyser = null;
                }
                
                isRecording = false;
            }
            
            async function handleRecordingStop() {
                logDebug('âºï¸ å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹å¤„ç†éŸ³é¢‘');
                
                try {
                    // åˆ›å»ºBlob
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    logDebug(`ğŸ’¾ åˆ›å»ºéŸ³é¢‘Blobï¼Œå¤§å°: ${audioBlob.size} bytes`);
                    
                    // æ˜¾ç¤ºå¤„ç†çŠ¶æ€
                    transcriptEl.classList.add('processing');
                    transcriptEl.innerHTML = '<div class="loading"></div> æ­£åœ¨å¤„ç†è¯­éŸ³...';
                    
                    // ä¸Šä¼ å½•éŸ³
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');
                    formData.append('source', 'mic_recording');
                    
                    logDebug('ğŸ“¤ å¼€å§‹ä¸Šä¼ éŸ³é¢‘æ•°æ®');
                    const response = await fetch('/transcribe', {
                        method: 'POST',
                        body: formData
                    });
                    
                    logDebug(`ğŸ“¡ æœåŠ¡å™¨å“åº”ï¼ŒçŠ¶æ€ç : ${response.status}`);
                    const result = await response.json();
                    
                    if (!response.ok) {
                        throw new Error(result.error || `æœåŠ¡å™¨é”™è¯¯: ${response.status}`);
                    }
                    
                    // æ˜¾ç¤ºç»“æœ
                    transcriptEl.classList.remove('processing');
                    const textContent = result.text || '[æœªè¯†åˆ«åˆ°å†…å®¹]';
                    
                    // ä¿ç•™æ¢è¡Œæ ¼å¼
                    const tempDiv = document.createElement('div');
                    tempDiv.textContent = textContent;
                    transcriptEl.innerHTML = tempDiv.innerHTML;
                    
                    logDebug('âœ… è½¬å½•å®Œæˆï¼Œæ˜¾ç¤ºç»“æœ');
                } catch (error) {
                    logDebug(`âŒ å¤„ç†å¤±è´¥: ${error.message}`, true);
                    transcriptEl.classList.remove('processing');
                    transcriptEl.innerHTML = `<span style="color: var(--danger)">âŒ è¯†åˆ«å¤±è´¥: ${error.message}</span>`;
                } finally {
                    resetUI();
                }
            }
            
            function resetUI() {
                logDebug('ğŸ”„ é‡ç½®UIçŠ¶æ€');
                recordingIndicator.classList.remove('active');
                recordBtn.classList.remove('recording');
                btnText.textContent = 'å¼€å§‹å½•éŸ³';
                recordBtn.disabled = false;
                voiceLevelFill.style.width = '0%';
                voiceLevelFill.className = 'voice-level-fill';
            }
        </script>
    </body>
    </html>
    """)

@app.route('/model-status')
def model_status():
    global model_error
    if model_error:
        return jsonify({"error": str(model_error)}), 500
    return jsonify({"loaded": model_loaded})

@app.route('/transcribe', methods=['POST'])
def transcribe_audio():
    global model, tokenizer, feature_extractor, config, device
    
    if not model_loaded:
        return jsonify({"error": "æ¨¡å‹å°šæœªåŠ è½½å®Œæˆ"}), 503
    
    try:
        audio_file = request.files['audio']
        source = request.form.get('source', 'mic_recording')  # 'mic_recording' æˆ– 'file_upload'
        if not audio_file:
            return jsonify({"error": "æœªæä¾›éŸ³é¢‘æ–‡ä»¶"}), 400
        
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmpfile:
            audio_path = Path(tmpfile.name)
            
            try:
                # å¤„ç†æ–‡ä»¶ä¸Šä¼  (é€šç”¨å¤„ç†æµç¨‹)
                from pydub import AudioSegment
                import io
                
                # è¯»å–ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
                file_content = audio_file.read()
                audio_data = io.BytesIO(file_content)
                
                # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                format_hint = get_audio_format(audio_file.filename)
                
                # è½¬æ¢ä¸º16kHz, å•å£°é“, 16-bit PCM WAV
                audio = AudioSegment.from_file(audio_data, format=format_hint)
                audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                audio.export(str(audio_path), format="wav")
                
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶è½¬æ¢æˆåŠŸ (æ¥æº: {source}, æ ¼å¼: {format_hint or 'auto'})")
            except Exception as e:
                # å›é€€æ–¹æ¡ˆï¼šå°è¯•ä½¿ç”¨ffmpeg
                try:
                    import subprocess
                    import sys
                    
                    # ä¿å­˜åŸå§‹æ–‡ä»¶
                    audio_file.seek(0)
                    with open(str(audio_path) + ".tmp", "wb") as f:
                        f.write(audio_file.read())
                    
                    # ä½¿ç”¨ffmpegè½¬æ¢
                    subprocess.run([
                        'ffmpeg', '-y',
                        '-i', str(audio_path) + ".tmp",
                        '-ar', '16000',
                        '-ac', '1',
                        '-sample_fmt', 's16',
                        str(audio_path)
                    ], check=True, capture_output=True)
                    
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    os.unlink(str(audio_path) + ".tmp")
                    print(f"âœ… éŸ³é¢‘æ–‡ä»¶è½¬æ¢æˆåŠŸ (ä½¿ç”¨ffmpeg, æ¥æº: {source})")
                except Exception as e2:
                    print(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {str(e)} | {str(e2)}")
                    return jsonify({"error": f"éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒæˆ–è½¬æ¢å¤±è´¥: {str(e)}"}), 400
        
        # ä½¿ç”¨å…¨å±€æ¨¡å‹è¿›è¡Œè½¬å½•
        with model_lock:  # ç¡®ä¿çº¿ç¨‹å®‰å…¨
            try:
                batch = build_prompt(
                    audio_path,
                    tokenizer,
                    feature_extractor,
                    merge_factor=config.merge_factor,
                )
                
                model_inputs, prompt_len = prepare_inputs(batch, device)
                
                with torch.inference_mode():
                    generated = model.generate(
                        **model_inputs,
                        max_new_tokens=128,
                        do_sample=False,
                    )
            
                # è·å–è½¬å½•ç»“æœ
                transcript_ids = generated[0, prompt_len:].cpu().tolist()
                transcript = tokenizer.decode(transcript_ids, skip_special_tokens=True).strip()
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if audio_path.exists():
                    audio_path.unlink()
        
        return jsonify({"text": transcript or "[æœªè¯†åˆ«åˆ°å†…å®¹]"})
    
    except Exception as e:
        error_msg = f"å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_msg)
        return jsonify({"error": str(e)}), 500

@app.route('/transcribe-segment', methods=['POST'])
def transcribe_audio_segment():
    """å¤„ç†éŸ³é¢‘åˆ†æ®µçš„è½¬å½•"""
    global model, tokenizer, feature_extractor, config, device
    
    if not model_loaded:
        return jsonify({"error": "æ¨¡å‹å°šæœªåŠ è½½å®Œæˆ"}), 503
    
    try:
        audio_file = request.files['audio']
        segment_index = int(request.form.get('segment_index', 0))
        total_segments = int(request.form.get('total_segments', 1))
        start_time = float(request.form.get('start_time', 0))
        end_time = float(request.form.get('end_time', 0))
        
        if not audio_file:
            return jsonify({"error": "æœªæä¾›éŸ³é¢‘åˆ†æ®µ"}), 400
        
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmpfile:
            audio_path = Path(tmpfile.name)
            
            try:
                # æ”¹è¿›çš„éŸ³é¢‘åˆ†æ®µå¤„ç†
                from pydub import AudioSegment
                import io
                
                file_content = audio_file.read()
                audio_data = io.BytesIO(file_content)
                
                # å°è¯•å¤šç§æ ¼å¼æ£€æµ‹
                format_hint = get_audio_format(audio_file.filename)
                
                # é¦–å…ˆå°è¯•ç›´æ¥åŠ è½½
                try:
                    audio = AudioSegment.from_file(audio_data, format=format_hint)
                except Exception as e:
                    # å°è¯•ä½¿ç”¨ä¸åŒçš„æ ¼å¼
                    print(f"é¦–æ¬¡åŠ è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ ¼å¼: {str(e)}")
                    
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    audio_data.seek(0)
                    
                    # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                    audio = AudioSegment.from_file(audio_data)
                
                # è®¾ç½®æ ‡å‡†æ ¼å¼
                audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                
                # å¦‚æœæ˜¯åˆ†æ®µï¼Œåªå¤„ç†ç›¸å…³éƒ¨åˆ†
                if start_time > 0 or end_time < audio.duration_seconds:
                    start_ms = int(start_time * 1000)
                    end_ms = int(end_time * 1000)
                    audio = audio[start_ms:end_ms]
                
                # å¯¼å‡ºä¸ºæ ‡å‡†WAV
                audio.export(str(audio_path), format="wav")
                
                print(f"âœ… éŸ³é¢‘åˆ†æ®µè½¬æ¢æˆåŠŸ (æ®µè½: {segment_index+1}/{total_segments}, æ—¶é•¿: {audio.duration_seconds:.2f}s)")
            except Exception as e:
                print(f"âŒ éŸ³é¢‘åˆ†æ®µå¤„ç†å¤±è´¥: {str(e)}")
                return jsonify({"error": f"éŸ³é¢‘åˆ†æ®µå¤„ç†å¤±è´¥: {str(e)}"}), 400
        
        # ä½¿ç”¨å…¨å±€æ¨¡å‹è¿›è¡Œè½¬å½•
        with model_lock:
            try:
                batch = build_prompt(
                    audio_path,
                    tokenizer,
                    feature_extractor,
                    merge_factor=config.merge_factor,
                )
                
                model_inputs, prompt_len = prepare_inputs(batch, device)
                
                with torch.inference_mode():
                    generated = model.generate(
                        **model_inputs,
                        max_new_tokens=128,
                        do_sample=False,
                    )
            
                # è·å–è½¬å½•ç»“æœ
                transcript_ids = generated[0, prompt_len:].cpu().tolist()
                transcript = tokenizer.decode(transcript_ids, skip_special_tokens=True).strip()
                
                # æ·»åŠ åˆ†æ®µæ ‡è®°
                if transcript:
                    transcript = f"[æ®µè½ {segment_index+1}/{total_segments}] {transcript}"
            finally:
                if audio_path.exists():
                    audio_path.unlink()
        
        return jsonify({
            "text": transcript or "[æœªè¯†åˆ«åˆ°å†…å®¹]",
            "segment_index": segment_index,
            "total_segments": total_segments
        })
    
    except Exception as e:
        error_msg = f"åˆ†æ®µå¤„ç†å¤±è´¥ (æ®µè½: {segment_index}): {str(e)}\n{traceback.format_exc()}"
        print(error_msg)
        return jsonify({"error": str(e)}), 500

def get_audio_format(filename):
    """æ™ºèƒ½æ£€æµ‹éŸ³é¢‘æ ¼å¼"""
    filename = filename.lower()
    if '.wav' in filename:
        return 'wav'
    elif '.mp3' in filename or '.mpeg' in filename:
        return 'mp3'
    elif '.m4a' in filename or '.mp4' in filename:
        return 'mp4'
    elif '.flac' in filename:
        return 'flac'
    elif '.ogg' in filename or '.webm' in filename:
        return 'ogg'
    elif '.aac' in filename:
        return 'aac'
    else:
        # å°è¯•ä»å†…å®¹æ£€æµ‹
        return None

# ========== æ¨¡å‹åŠ è½½ ==========
def load_model(checkpoint_dir: Path, tokenizer_path: str, device_str: str):
    global model, tokenizer, feature_extractor, config, device, model_loaded, model_error
    
    try:
        print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        print(f"  æ¨¡å‹è·¯å¾„: {checkpoint_dir}")
        print(f"  è®¾å¤‡: {device_str}")
        
        device = torch.device(device_str)
        
        # åŠ è½½tokenizer
        print("  åŠ è½½tokenizer...")
        tokenizer_source = tokenizer_path if tokenizer_path else checkpoint_dir
        tokenizer = AutoTokenizer.from_pretrained(tokenizer_source)
        
        # åŠ è½½ç‰¹å¾æå–å™¨
        print("  åŠ è½½ç‰¹å¾æå–å™¨...")
        feature_extractor = WhisperFeatureExtractor(**WHISPER_FEAT_CFG)

        # åŠ è½½æ¨¡å‹é…ç½®
        print("  åŠ è½½æ¨¡å‹é…ç½®...")
        config = AutoConfig.from_pretrained(checkpoint_dir, trust_remote_code=True)
        
        # åŠ è½½æ¨¡å‹
        print("  åŠ è½½æ¨¡å‹æƒé‡ (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
        model = AutoModelForCausalLM.from_pretrained(
            checkpoint_dir,
            config=config,
            torch_dtype=torch.bfloat16,
            trust_remote_code=True,
        )
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        print(f"  å°†æ¨¡å‹ç§»åŠ¨åˆ° {device_str}...")
        model = model.to(device)
        model.eval()
        
        model_loaded = True
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼æœåŠ¡å·²å°±ç»ª")
    except Exception as e:
        model_error = e
        error_msg = f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_msg)
        raise

# ========== å¯åŠ¨ ==========
def main():
    parser = argparse.ArgumentParser(description="Web ASR transcription demo with silence detection and file upload.")
    parser.add_argument(
        "--checkpoint_dir", type=str, default=str(Path(__file__).parent)
    )
    parser.add_argument(
        "--tokenizer_path",
        type=str,
        default=None,
        help="Tokenizer directory (defaults to checkpoint dir when omitted).",
    )
    parser.add_argument(
        "--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu"
    )
    parser.add_argument("--host", type=str, default="127.0.0.1")
    parser.add_argument("--port", type=int, default=5000)
    args = parser.parse_args()

    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    try:
        from pydub import AudioSegment
        print("âœ… pydub ä¾èµ–å·²å®‰è£…ï¼Œæ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼è½¬æ¢")
    except ImportError:
        print("âŒ æœªå®‰è£… pydubï¼Œæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½å°†æ— æ³•ä½¿ç”¨")
        print("   è¯·å®‰è£…: pip install pydub")
        print("   å¹¶ç¡®ä¿ç³»ç»Ÿå·²å®‰è£…ffmpeg (sudo apt-get install ffmpeg æˆ– brew install ffmpeg)")
        exit(1)
    
    try:
        import ffmpeg
        print("âœ… ffmpeg-python ä¾èµ–å·²å®‰è£…")
    except ImportError:
        print("â„¹ï¸ æœªå®‰è£… ffmpeg-pythonï¼Œå°†ä½¿ç”¨ç³»ç»Ÿffmpegå‘½ä»¤")
    
    print("\n" + "="*50)
    print("å…¨èƒ½è¯­éŸ³è¯†åˆ«WebæœåŠ¡å¯åŠ¨ä¸­...")
    print(f"æ¨¡å‹ç›®å½•: {args.checkpoint_dir}")
    print(f"è®¾å¤‡: {args.device}")
    print(f"è®¿é—®åœ°å€: http://127.0.0.1:{args.port}")
    print("="*50 + "\n")
    
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("  1. æœåŠ¡å¯åŠ¨åï¼Œæ‰“å¼€æµè§ˆå™¨è®¿é—®ä¸Šè¿°åœ°å€")
    print("  2. é¦–æ¬¡ä½¿ç”¨éº¦å…‹é£æ—¶è¯·å…è®¸æƒé™")
    print("  3. å¯ä»¥é€šè¿‡é€‰é¡¹å¡åˆ‡æ¢ã€Œéº¦å…‹é£å½•éŸ³ã€å’Œã€Œä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ã€æ¨¡å¼")
    print("  4. éº¦å…‹é£å½•éŸ³æ”¯æŒé™éŸ³è‡ªåŠ¨åœæ­¢åŠŸèƒ½")
    print("  5. ä¸Šä¼ é•¿éŸ³é¢‘æ–‡ä»¶ä¼šè‡ªåŠ¨åˆ†æ®µå¤„ç†ï¼Œå®æ—¶æ˜¾ç¤ºè¿›åº¦å’Œç»“æœ\n")

    # å¯åŠ¨åå°çº¿ç¨‹åŠ è½½æ¨¡å‹
    loader_thread = threading.Thread(
        target=load_model,
        args=(Path(args.checkpoint_dir), args.tokenizer_path, args.device),
        daemon=True
    )
    loader_thread.start()
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(host=args.host, port=args.port, threaded=True, use_reloader=False)

if __name__ == "__main__":
    main()